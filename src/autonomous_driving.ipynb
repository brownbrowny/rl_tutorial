{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet\n",
      "  Downloading pyglet-2.0.14-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: gym[box2d] in /home/aaron/rl_tutorial/lib/python3.8/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/aaron/rl_tutorial/lib/python3.8/site-packages (from gym[box2d]) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/aaron/rl_tutorial/lib/python3.8/site-packages (from gym[box2d]) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/aaron/rl_tutorial/lib/python3.8/site-packages (from gym[box2d]) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/aaron/rl_tutorial/lib/python3.8/site-packages (from gym[box2d]) (7.0.2)\n",
      "Collecting box2d-py==2.3.5 (from gym[box2d])\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pygame==2.1.0 (from gym[box2d])\n",
      "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting swig==4.* (from gym[box2d])\n",
      "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/aaron/rl_tutorial/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.18.1)\n",
      "Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pyglet-2.0.14-py3-none-any.whl (876 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m876.8/876.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp38-cp38-linux_x86_64.whl size=2804862 sha256=c80c7cd291e3b600a0cc526df706dcb314c1e96f5c763e45baf9176d2fafc989\n",
      "  Stored in directory: /home/aaron/.cache/pip/wheels/8b/95/16/1dc99ff9a3f316ff245fdb5c9086cd13c35dad630809909075\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: swig, box2d-py, pyglet, pygame\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.5.2\n",
      "    Uninstalling pygame-2.5.2:\n",
      "      Successfully uninstalled pygame-2.5.2\n",
      "Successfully installed box2d-py-2.3.5 pygame-2.1.0 pyglet-2.0.14 swig-4.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[box2d] pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "Box(0, 255, (96, 96, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \tenv\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     10\u001b[0m \taction \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 11\u001b[0m \tobs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \tscore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:541\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:603\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    600\u001b[0m trans \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[38;5;241m.\u001b[39mrotate_rad(angle)\n\u001b[1;32m    601\u001b[0m trans \u001b[38;5;241m=\u001b[39m (WINDOW_W \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m0\u001b[39m], WINDOW_H \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_road\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    606\u001b[0m     zoom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m     mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    610\u001b[0m )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:665\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[0;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[1;32m    656\u001b[0m         grass\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    657\u001b[0m             [\n\u001b[1;32m    658\u001b[0m                 (GRASS_DIM \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m GRASS_DIM, GRASS_DIM \u001b[38;5;241m*\u001b[39m y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m             ]\n\u001b[1;32m    663\u001b[0m         )\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly \u001b[38;5;129;01min\u001b[39;00m grass:\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_colored_polygon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrass_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# draw road\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad_poly:\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;66;03m# converting to pixel coordinates\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:761\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[0;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# This checks if the polygon is out of bounds of the screen, and we skip drawing if so.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# Instead of calculating exactly if the polygon and screen overlap,\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# we simply check if the polygon is in a larger bounding box whose dimension\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# is greater than the screen by MAX_SHAPE_DIM, which is the maximum\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# diagonal length of an environment object\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m clip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    757\u001b[0m     (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_W \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_H \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m poly\n\u001b[1;32m    760\u001b[0m ):\n\u001b[0;32m--> 761\u001b[0m     \u001b[43mgfxdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maapolygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39mfilled_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "\tobs = env.reset()\n",
    "\tdone = False\n",
    "\tscore = 0\n",
    " \n",
    "\twhile not done:\n",
    "\t\tenv.render()\n",
    "\t\taction = env.action_space.sample()\n",
    "\t\tobs, reward, done, truncated, info = env.step(action)\n",
    "\t\tscore += reward\n",
    "\tprint(f'Episode: {episode}, Score: {score}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v2')\n",
    "env = DummyVecEnv([lambda: env])    # The algorithms require a vectorized environment to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('training', 'logs')\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training/logs/PPO_10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 74   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 27   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058309226 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.25        |\n",
      "|    explained_variance   | -0.0102      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.352        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 0.628        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054185083 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.0666       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.485        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00749583 |\n",
      "|    clip_fraction        | 0.0921     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.22      |\n",
      "|    explained_variance   | 0.102      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00772   |\n",
      "|    std                  | 0.983      |\n",
      "|    value_loss           | 0.448      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008713437 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.503       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124553 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0631      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007147013 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013050307 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01156822 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.14      |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.132      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    std                  | 0.956      |\n",
      "|    value_loss           | 0.3        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016099878 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014952436 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016601257 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0368      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949997 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0565      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    std                  | 0.923       |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020076167 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 607        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02279963 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.96      |\n",
      "|    explained_variance   | 0.911      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0219     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 0.905      |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016667202 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00437    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026602937 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0431      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022985954 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 772         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023142383 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0413      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027417898 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.033      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017557666 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 50        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 890       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0252216 |\n",
      "|    clip_fraction        | 0.208     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.75     |\n",
      "|    explained_variance   | 0.963     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0163    |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -0.0205   |\n",
      "|    std                  | 0.847     |\n",
      "|    value_loss           | 0.0668    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 927         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025467347 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0109      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 0.0823      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 965         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020095805 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00226    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1001        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025706269 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00893     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 0.0949      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 1039       |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03654242 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.62      |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0192    |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    std                  | 0.813      |\n",
      "|    value_loss           | 0.142      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1078        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023192648 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00853    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    std                  | 0.796       |\n",
      "|    value_loss           | 0.0845      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030500637 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 0.788       |\n",
      "|    value_loss           | 0.0402      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 51         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 1154       |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02481832 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.51      |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0248    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    std                  | 0.783      |\n",
      "|    value_loss           | 0.045      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021379957 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.781       |\n",
      "|    value_loss           | 0.0577      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1228        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030463912 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0373     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    std                  | 0.783       |\n",
      "|    value_loss           | 0.0646      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1264        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037034575 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0365     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    std                  | 0.785       |\n",
      "|    value_loss           | 0.0581      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1299        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036919437 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0546     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    std                  | 0.781       |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1336        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020324916 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.778       |\n",
      "|    value_loss           | 0.0333      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1374        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037260912 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0383     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    std                  | 0.776       |\n",
      "|    value_loss           | 0.0359      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 1411       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03578765 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.45      |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0615    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0361    |\n",
      "|    std                  | 0.769      |\n",
      "|    value_loss           | 0.0279     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1446        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028720371 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0202     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    std                  | 0.763       |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1482       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03333191 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.4       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.034     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    std                  | 0.756      |\n",
      "|    value_loss           | 0.0265     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 1516       |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04312495 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.39      |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0706    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    std                  | 0.754      |\n",
      "|    value_loss           | 0.0574     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 52        |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 1553      |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0362517 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.36     |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0214   |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -0.0258   |\n",
      "|    std                  | 0.743     |\n",
      "|    value_loss           | 0.0582    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 1588       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04622948 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.34      |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0392    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    std                  | 0.743      |\n",
      "|    value_loss           | 0.0369     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1626       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03335817 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.32      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00714   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    std                  | 0.737      |\n",
      "|    value_loss           | 0.0606     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1663        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049064808 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0437     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    std                  | 0.732       |\n",
      "|    value_loss           | 0.0568      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 1698       |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03739932 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.28      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0359    |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    std                  | 0.727      |\n",
      "|    value_loss           | 0.0498     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1733        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048996314 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0505     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 0.0492      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1773        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040598158 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0388     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    std                  | 0.71        |\n",
      "|    value_loss           | 0.0795      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 1809      |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0370571 |\n",
      "|    clip_fraction        | 0.257     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.18     |\n",
      "|    explained_variance   | 0.982     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0567   |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -0.0295   |\n",
      "|    std                  | 0.703     |\n",
      "|    value_loss           | 0.0649    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1844        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056536194 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 0.0421      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:194\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 194\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/vec_transpose.py:97\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 97\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/shimmy/openai_gym_compatibility.py:117\u001b[0m, in \u001b[0;36mGymV26CompatibilityV0.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:541\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:603\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    600\u001b[0m trans \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[38;5;241m.\u001b[39mrotate_rad(angle)\n\u001b[1;32m    601\u001b[0m trans \u001b[38;5;241m=\u001b[39m (WINDOW_W \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m0\u001b[39m], WINDOW_H \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_road\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    606\u001b[0m     zoom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m     mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    610\u001b[0m )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:674\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[0;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[1;32m    672\u001b[0m poly \u001b[38;5;241m=\u001b[39m [(p[\u001b[38;5;241m0\u001b[39m], p[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m poly]\n\u001b[1;32m    673\u001b[0m color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color]\n\u001b[0;32m--> 674\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_colored_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:761\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[0;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# This checks if the polygon is out of bounds of the screen, and we skip drawing if so.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# Instead of calculating exactly if the polygon and screen overlap,\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# we simply check if the polygon is in a larger bounding box whose dimension\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# is greater than the screen by MAX_SHAPE_DIM, which is the maximum\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# diagonal length of an environment object\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m clip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    757\u001b[0m     (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_W \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_H \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m poly\n\u001b[1;32m    760\u001b[0m ):\n\u001b[0;32m--> 761\u001b[0m     \u001b[43mgfxdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maapolygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39mfilled_polygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('training', 'saved_models', 'PPO_Driving_Model')\n",
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(ppo_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode=\"human\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/home/aaron/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:94\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     88\u001b[0m     actions, states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m     89\u001b[0m         observations,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         state\u001b[38;5;241m=\u001b[39mstates,\n\u001b[1;32m     91\u001b[0m         episode_start\u001b[38;5;241m=\u001b[39mepisode_starts,\n\u001b[1;32m     92\u001b[0m         deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0m     new_observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     current_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n\u001b[1;32m     96\u001b[0m     current_lengths \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/shimmy/openai_gym_compatibility.py:117\u001b[0m, in \u001b[0;36mGymV26CompatibilityV0.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:541\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/gym/envs/box2d/car_racing.py:617\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# showing stats\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_indicators(WINDOW_W, WINDOW_H)\n\u001b[0;32m--> 617\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m text \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%04i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward, \u001b[38;5;28;01mTrue\u001b[39;00m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    619\u001b[0m text_rect \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mget_rect()\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/pygame/pkgdata.py:67\u001b[0m, in \u001b[0;36mgetResource\u001b[0;34m(identifier, pkgname)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resource_exists(pkgname, identifier):\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresource_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkgname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/pkg_resources/__init__.py:1187\u001b[0m, in \u001b[0;36mResourceManager.resource_stream\u001b[0;34m(self, package_or_requirement, resource_name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresource_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, package_or_requirement, resource_name):\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a readable file-like object for specified resource\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage_or_requirement\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_resource_stream(\n\u001b[1;32m   1188\u001b[0m         \u001b[38;5;28mself\u001b[39m, resource_name\n\u001b[1;32m   1189\u001b[0m     )\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/pkg_resources/__init__.py:391\u001b[0m, in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    389\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[moduleOrReq]\n\u001b[1;32m    390\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__loader__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_provider_factories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/pkg_resources/__init__.py:1665\u001b[0m, in \u001b[0;36mEggProvider.__init__\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, module):\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(module)\n\u001b[0;32m-> 1665\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/pkg_resources/__init__.py:1671\u001b[0m, in \u001b[0;36mEggProvider._setup_prefix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_prefix\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;66;03m# Assume that metadata may be nested inside a \"basket\"\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;66;03m# of multiple eggs and use module_path instead of .archive.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m     eggs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(_is_egg_path, _parents(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_path))\n\u001b[0;32m-> 1671\u001b[0m     egg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meggs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1672\u001b[0m     egg \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_egg(egg)\n",
      "File \u001b[0;32m~/rl_tutorial/lib/python3.8/site-packages/pkg_resources/__init__.py:1657\u001b[0m, in \u001b[0;36m_parents\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m path\n\u001b[1;32m   1656\u001b[0m last \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m-> 1657\u001b[0m path, _ \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/posixpath.py:107\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    105\u001b[0m i \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mrfind(sep) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    106\u001b[0m head, tail \u001b[38;5;241m=\u001b[39m p[:i], p[i:]\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m head \u001b[38;5;241m!=\u001b[39m sep\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mlen\u001b[39;49m(head):\n\u001b[1;32m    108\u001b[0m     head \u001b[38;5;241m=\u001b[39m head\u001b[38;5;241m.\u001b[39mrstrip(sep)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m head, tail\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8), {})\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "print(type(obs))\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m      8\u001b[0m \tenv\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m----> 9\u001b[0m \tobs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     10\u001b[0m \taction, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs[\u001b[38;5;241m0\u001b[39m])\t\u001b[38;5;66;03m# now using the model prediction\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \tobs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "\tobs = env.reset()\t# reset environment to initial state and get initial observation\n",
    "\tdone = False\n",
    "\tscore = 0\n",
    "\n",
    "\twhile not done:\n",
    "\t\tenv.render()\n",
    "\t\tobs = np.array(obs).reshape(1, 96, 96, 3)\n",
    "\t\taction, _ = model.predict(obs[0])\t# now using the model prediction\n",
    "\t\tobs, reward, done, truncated, info = env.step(action)\n",
    "\t\tscore += reward\n",
    "\tprint(f'Episode: {episode}, Score: {score}')\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
